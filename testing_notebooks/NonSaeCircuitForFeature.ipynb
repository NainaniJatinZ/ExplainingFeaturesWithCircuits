{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814d58aa-5bb4-4631-b648-5b6bfefd4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f72619178824dd3b2913c13ef000e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n",
      "Tokenized prompt: ['<bos>', 'What', ' is', ' the', ' output', ' of', ' ', '5', '3', ' plus', ' ', '3', '4', ' ?', ' It', ' is', ' ']\n",
      "Tokenized answer: [' ', '8']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2412</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.78</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m2412\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m9.78\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 27.23 Prob: 54.42% Token: |8|\n",
      "Top 1th token. Logit: 25.61 Prob: 10.80% Token: |5|\n",
      "Top 2th token. Logit: 25.38 Prob:  8.58% Token: |1|\n",
      "Top 3th token. Logit: 24.99 Prob:  5.78% Token: |2|\n",
      "Top 4th token. Logit: 24.60 Prob:  3.92% Token: |3|\n",
      "Top 5th token. Logit: 24.43 Prob:  3.30% Token: |<strong>|\n",
      "Top 6th token. Logit: 24.13 Prob:  2.47% Token: |4|\n",
      "Top 7th token. Logit: 24.03 Prob:  2.23% Token: |________________|\n",
      "Top 8th token. Logit: 23.97 Prob:  2.09% Token: |6|\n",
      "Top 9th token. Logit: 23.95 Prob:  2.06% Token: |7|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.26</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.73</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m25.26\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m26.73\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 25.26 Prob: 26.73% Token: |8|\n",
      "Top 1th token. Logit: 24.54 Prob: 13.10% Token: |1|\n",
      "Top 2th token. Logit: 24.53 Prob: 12.87% Token: |5|\n",
      "Top 3th token. Logit: 24.14 Prob:  8.76% Token: |2|\n",
      "Top 4th token. Logit: 23.82 Prob:  6.35% Token: |<strong>|\n",
      "Top 5th token. Logit: 23.81 Prob:  6.29% Token: |3|\n",
      "Top 6th token. Logit: 23.60 Prob:  5.12% Token: |6|\n",
      "Top 7th token. Logit: 23.47 Prob:  4.46% Token: |4|\n",
      "Top 8th token. Logit: 23.44 Prob:  4.36% Token: |________________|\n",
      "Top 9th token. Logit: 23.36 Prob:  4.01% Token: |7|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2412</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'8'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m2412\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'8'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "# Imports for displaying vis in Colab / notebook\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# For the most part I'll try to import functions and classes near where they are used\n",
    "# to make it clear where they come from.\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "# from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "model = HookedSAETransformer.from_pretrained(\"google/gemma-2-2b\", device = device)\n",
    "\n",
    "\n",
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "prompt = \"What is the output of 53 plus 34 ? It is \"\n",
    "answer = '8'\n",
    "# Show that the model can confidently predict the next token.\n",
    "test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c7627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: layer_0/width_16k/average_l0_105\n",
      "Layer 1: layer_1/width_16k/average_l0_102\n",
      "Layer 2: layer_2/width_16k/average_l0_141\n",
      "Layer 3: layer_3/width_16k/average_l0_59\n",
      "Layer 4: layer_4/width_16k/average_l0_124\n",
      "Layer 5: layer_5/width_16k/average_l0_68\n",
      "Layer 6: layer_6/width_16k/average_l0_70\n",
      "Layer 7: layer_7/width_16k/average_l0_69\n",
      "Layer 8: layer_8/width_16k/average_l0_71\n",
      "Layer 9: layer_9/width_16k/average_l0_73\n",
      "Layer 10: layer_10/width_16k/average_l0_77\n",
      "Layer 11: layer_11/width_16k/average_l0_80\n",
      "Layer 12: layer_12/width_16k/average_l0_82\n",
      "Layer 13: layer_13/width_16k/average_l0_84\n",
      "Layer 14: layer_14/width_16k/average_l0_84\n",
      "Layer 15: layer_15/width_16k/average_l0_78\n",
      "Layer 16: layer_16/width_16k/average_l0_78\n",
      "Layer 17: layer_17/width_16k/average_l0_77\n",
      "Layer 18: layer_18/width_16k/average_l0_74\n",
      "Layer 19: layer_19/width_16k/average_l0_73\n",
      "Layer 20: layer_20/width_16k/average_l0_71\n",
      "Layer 21: layer_21/width_16k/average_l0_70\n",
      "Layer 22: layer_22/width_16k/average_l0_72\n",
      "Layer 23: layer_23/width_16k/average_l0_75\n",
      "Layer 24: layer_24/width_16k/average_l0_73\n",
      "Layer 25: layer_25/width_16k/average_l0_116\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "\n",
    "# TODO: Make this nicer.\n",
    "df = pd.DataFrame.from_records({k:v.__dict__ for k,v in get_pretrained_saes_directory().items()}).T\n",
    "df.drop(columns=[\"expected_var_explained\", \"expected_l0\", \"config_overrides\", \"conversion_func\"], inplace=True)\n",
    "df[df['model']=='gemma-2-2b']\n",
    "sae_keys = list(df.loc['gemma-scope-2b-pt-res']['saes_map'].keys())\n",
    "# Dictionary to store the closest string for each layer\n",
    "closest_strings = {}\n",
    "\n",
    "# Regular expression to extract the layer number and l0 value\n",
    "pattern = re.compile(r'layer_(\\d+)/width_16k/average_l0_(\\d+)')\n",
    "\n",
    "# Organize strings by layer\n",
    "layer_dict = defaultdict(list)\n",
    "\n",
    "for s in sae_keys:\n",
    "    match = pattern.search(s)\n",
    "    if match:\n",
    "        layer = int(match.group(1))\n",
    "        l0_value = int(match.group(2))\n",
    "        layer_dict[layer].append((s, l0_value))\n",
    "\n",
    "# Find the string with l0 value closest to 100 for each layer\n",
    "for layer, items in layer_dict.items():\n",
    "    closest_string = min(items, key=lambda x: abs(x[1] - 100))\n",
    "    closest_strings[layer] = closest_string[0]\n",
    "\n",
    "# Output the closest string for each layer\n",
    "for layer in sorted(closest_strings):\n",
    "    print(f\"Layer {layer}: {closest_strings[layer]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6066ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the output of 38 plus 33 ? It is ',\n",
       " 'What is the output of 58 plus 19 ? It is ',\n",
       " 'What is the output of 67 plus 44 ? It is ',\n",
       " 'What is the output of 49 plus 25 ? It is ',\n",
       " 'What is the output of 32 plus 61 ? It is ',\n",
       " 'What is the output of 16 plus 68 ? It is ',\n",
       " 'What is the output of 61 plus 54 ? It is ',\n",
       " 'What is the output of 48 plus 39 ? It is ',\n",
       " 'What is the output of 64 plus 40 ? It is ',\n",
       " 'What is the output of 10 plus 14 ? It is ',\n",
       " 'What is the output of 70 plus 41 ? It is ',\n",
       " 'What is the output of 48 plus 61 ? It is ',\n",
       " 'What is the output of 67 plus 56 ? It is ',\n",
       " 'What is the output of 28 plus 21 ? It is ',\n",
       " 'What is the output of 10 plus 56 ? It is ',\n",
       " 'What is the output of 43 plus 46 ? It is ',\n",
       " 'What is the output of 38 plus 62 ? It is ',\n",
       " 'What is the output of 56 plus 42 ? It is ',\n",
       " 'What is the output of 31 plus 36 ? It is ',\n",
       " 'What is the output of 58 plus 50 ? It is ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_number_variations(prompt, num_variations=5):\n",
    "    variations = []\n",
    "    for _ in range(num_variations):\n",
    "        num1 = random.randint(10, 70)\n",
    "        num2 = random.randint(10, 70)\n",
    "        new_prompt = prompt.replace(\"53\", str(num1)).replace(\"34\", str(num2))\n",
    "        tokens = model.to_str_tokens(new_prompt)\n",
    "        # print(tokens)\n",
    "        # num1_pos = tokens.index(str(num1)[0])\n",
    "        # num2_pos = tokens.index(str(num2)[0])\n",
    "        # operation_pos = tokens.index(' plus')\n",
    "        # question_pos = tokens.index(' ?')\n",
    "        variations.append(new_prompt)\n",
    "    return variations\n",
    "\n",
    "prompt = \"What is the output of 53 plus 34 ? It is \"\n",
    "number_variations = generate_number_variations(prompt, 20)\n",
    "number_variations\n",
    "# 7, 8, 9, 11, 12, 13, -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcba699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"gemma-scope-2b-pt-res\", # <- Release name \n",
    "    sae_id = \"layer_8/width_16k/average_l0_71\", # <- SAE id (not always a hook point!)\n",
    "    device = device\n",
    ")\n",
    "pr = 'What is the output of 53 plus 32 ? A: '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548841b-7cd4-4e15-9757-cf9560ca70a2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2055bb7b-fafc-4234-a8af-c2fb441fd05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "  Clean:     What is the output of 54 plus 67 ? \n",
      "  Corrupted: What is the output of 54 and 67 ? \n",
      "\n",
      "Pair 2:\n",
      "  Clean:     What is the output of 54 plus 84 ? \n",
      "  Corrupted: What is the output of 54 and 84 ? \n",
      "\n",
      "Pair 3:\n",
      "  Clean:     What is the output of 75 plus 20 ? \n",
      "  Corrupted: What is the output of 75 and 20 ? \n",
      "\n",
      "Pair 4:\n",
      "  Clean:     What is the output of 26 plus 80 ? \n",
      "  Corrupted: What is the output of 26 and 80 ? \n",
      "\n",
      "Pair 5:\n",
      "  Clean:     What is the output of 85 plus 29 ? \n",
      "  Corrupted: What is the output of 85 and 29 ? \n",
      "\n",
      "Pair 6:\n",
      "  Clean:     What is the output of 81 plus 33 ? \n",
      "  Corrupted: What is the output of 81 and 33 ? \n",
      "\n",
      "Pair 7:\n",
      "  Clean:     What is the output of 87 plus 85 ? \n",
      "  Corrupted: What is the output of 87 and 85 ? \n",
      "\n",
      "Pair 8:\n",
      "  Clean:     What is the output of 92 plus 41 ? \n",
      "  Corrupted: What is the output of 92 and 41 ? \n",
      "\n",
      "Pair 9:\n",
      "  Clean:     What is the output of 11 plus 95 ? \n",
      "  Corrupted: What is the output of 11 and 95 ? \n",
      "\n",
      "Pair 10:\n",
      "  Clean:     What is the output of 54 plus 57 ? \n",
      "  Corrupted: What is the output of 54 and 57 ? \n",
      "\n",
      "Pair 11:\n",
      "  Clean:     What is the output of 55 plus 44 ? \n",
      "  Corrupted: What is the output of 55 and 44 ? \n",
      "\n",
      "Pair 12:\n",
      "  Clean:     What is the output of 67 plus 52 ? \n",
      "  Corrupted: What is the output of 67 and 52 ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_example_pair():\n",
    "    # Generate two random numbers between 1 and 3 digits\n",
    "    num1 = random.randint(10, 99)\n",
    "    num2 = random.randint(10, 99)\n",
    "    \n",
    "    # Create clean and corrupted examples\n",
    "    clean_example = f'What is the output of {num1} plus {num2} ? '\n",
    "    corrupted_example = f'What is the output of {num1} and {num2} ? '\n",
    "    \n",
    "    return clean_example, corrupted_example\n",
    "\n",
    "def generate_dataset(N):\n",
    "    dataset = []\n",
    "    for _ in range(N):\n",
    "        clean, corrupted = generate_example_pair()\n",
    "        dataset.append((clean, corrupted))\n",
    "    return dataset\n",
    "\n",
    "# Example usage\n",
    "N = 100  # Number of pairs to generate\n",
    "dataset = generate_dataset(N)\n",
    "\n",
    "# Print the dataset\n",
    "for i, (clean, corrupted) in enumerate(dataset):\n",
    "    print(f\"Pair {i+1}:\")\n",
    "    print(f\"  Clean:     {clean}\")\n",
    "    print(f\"  Corrupted: {corrupted}\")\n",
    "    print()\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b6fce9-6843-4fee-b7f2-3fc30e434a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.8.hook_resid_post'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg.hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f133a409-3320-402d-a50a-18d095f4b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pr = []\n",
    "corr_pr = []\n",
    "for i, (clean, corrupted) in enumerate(dataset):\n",
    "    clean_pr.append(clean)\n",
    "    corr_pr.append(corrupted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72d62f",
   "metadata": {},
   "source": [
    "# Code to run a feature from normal cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bbc5b-40f1-4a0d-aa0f-e83f7579e72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa9cec98-3d55-4e60-8215-7a8fc6d6392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_till_feature(prompt):\n",
    "    _, cache = model.run_with_cache(\n",
    "            prompt, \n",
    "            stop_at_layer=sae.cfg.hook_layer + 1, \n",
    "            names_filter=[sae.cfg.hook_name])\n",
    "    sae_in = cache[sae.cfg.hook_name]\n",
    "    feature_acts = sae.encode(sae_in).squeeze()\n",
    "    return feature_acts[:, 15191][-2:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4026f397-7ed7-4de6-8d49-3d57f8abae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean:  tensor(5.4081, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.6722, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.2776, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.1121, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.4368, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.7264, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.8089, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.0535, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.7028, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.7939, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.1387, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.3161, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.7129, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.5915, device='cuda:0')\n",
      "Corrupted:  tensor(2.5286, device='cuda:0')\n",
      "Clean:  tensor(12.8463, device='cuda:0')\n",
      "Corrupted:  tensor(3.2150, device='cuda:0')\n",
      "Clean:  tensor(11.2049, device='cuda:0')\n",
      "Corrupted:  tensor(3.2355, device='cuda:0')\n",
      "Clean:  tensor(7.1276, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.8910, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.7467, device='cuda:0')\n",
      "Corrupted:  tensor(2.8537, device='cuda:0')\n",
      "Clean:  tensor(11.5265, device='cuda:0')\n",
      "Corrupted:  tensor(2.3098, device='cuda:0')\n",
      "Clean:  tensor(11.4058, device='cuda:0')\n",
      "Corrupted:  tensor(2.3853, device='cuda:0')\n",
      "Clean:  tensor(9.0390, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.6839, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.4592, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.8225, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.2212, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.9476, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.8388, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.6019, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.1981, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(13.5492, device='cuda:0')\n",
      "Corrupted:  tensor(2.7718, device='cuda:0')\n",
      "Clean:  tensor(5.5911, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.7593, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.1755, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.0025, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.9160, device='cuda:0')\n",
      "Corrupted:  tensor(2.7567, device='cuda:0')\n",
      "Clean:  tensor(9.5073, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.3691, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.7765, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.2268, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.6724, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.4597, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.5471, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.1143, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.0054, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.0350, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.8876, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.7432, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.5361, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(11.2677, device='cuda:0')\n",
      "Corrupted:  tensor(3.4606, device='cuda:0')\n",
      "Clean:  tensor(8.7295, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(12.0233, device='cuda:0')\n",
      "Corrupted:  tensor(2.4556, device='cuda:0')\n",
      "Clean:  tensor(6.0063, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.7312, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.8344, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.7205, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.9591, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.1754, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.9031, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.9048, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.9031, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.6647, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.3944, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.2317, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.8939, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.8883, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.4691, device='cuda:0')\n",
      "Corrupted:  tensor(2.4892, device='cuda:0')\n",
      "Clean:  tensor(9.4328, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.2623, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(12.8435, device='cuda:0')\n",
      "Corrupted:  tensor(2.6791, device='cuda:0')\n",
      "Clean:  tensor(10.1449, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.6480, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(11.1772, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.8587, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.4818, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(4.7500, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.7857, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(4.8198, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.2481, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.5781, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.1699, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(5.9199, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.3428, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.2926, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.3566, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.0010, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.9599, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(10.3139, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.5881, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.4307, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.1010, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.0817, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(9.6315, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.8982, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(7.2738, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(4.8198, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(8.6097, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(4.8583, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(6.7920, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n",
      "Clean:  tensor(3.7504, device='cuda:0')\n",
      "Corrupted:  tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, (clean, corrupted) in enumerate(dataset):\n",
    "    print(\"Clean: \", run_model_till_feature(clean))\n",
    "    print(\"Corrupted: \", run_model_till_feature(corrupted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3fe574-e4e9-45b0-b547-debf0b1eb80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.8.hook_resid_post'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg.hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b227c7-b2b5-4424-aed9-9f742b05f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "            number_variations[0:5], \n",
    "            stop_at_layer=sae.cfg.hook_layer + 1, \n",
    "            names_filter=[sae.cfg.hook_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5549207f-d0be-4bb7-8a02-3d38d606dff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 17, 2304])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[sae.cfg.hook_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30e6110-2c9a-4842-adc5-cdfa1f2273ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 16384])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_in = cache[sae.cfg.hook_name]\n",
    "feature_acts = sae.encode(sae_in).squeeze()\n",
    "feature_acts = feature_acts.flatten(0, 1)\n",
    "feature_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8d2a3c-9f89-4eaf-8c94-b40ce4ac8c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.202563285827637"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_acts[:, 15191].max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb8e51c-0f26-4cee-8397-d7c8a82063d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_in = cache[sae.cfg.hook_name]\n",
    "feature_acts = sae.encode(sae_in).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53ade0-1ca5-4f81-b6db-61dba5741520",
   "metadata": {},
   "outputs": [],
   "source": [
    "'<bos>', 'What', ' is', ' the', ' output', ' of', ' ', '5', '3', ' plus', ' ', '3', '4', ' ?', ' It', ' is', ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e6b5ccf-f577-4a14-b9bc-ebcf51025b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  2.4291,  0.0000,  0.0000,  7.2193,  0.0000,  2.6175,\n",
       "        11.4568], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_acts[:, 15191] #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91543a1-33ec-4ef8-82bf-6b0210de17a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0349,  0.0009,  0.0382,  ..., -0.0309, -0.0299,  0.0056],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.W_dec[15191]#.to(model.cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06489519-e5ac-40fc-87dc-3f554d27fb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180fb00-59cf-41e9-9853-4832878a88bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c56de-57e3-4f58-a46e-756ff27be0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ab4c2c8",
   "metadata": {},
   "source": [
    "# Logit diff replaced by feature activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0f39f2-78e6-4008-84cb-1074c924dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.ActivationCache import ActivationCache\n",
    "from transformer_lens.HookedTransformer import HookedTransformer\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "from functools import partial\n",
    "from typing import Callable, Optional, Sequence, Tuple, Union, overload\n",
    "\n",
    "import einops\n",
    "import pandas as pd\n",
    "import torch\n",
    "from jaxtyping import Float, Int\n",
    "from tqdm.auto import tqdm\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import types\n",
    "from transformer_lens.utils import Slice, SliceInput\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5a67b8-c6d6-4ec4-a2c0-0a3bf9d7bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_cache_with_extra_hook(\n",
    "    self,\n",
    "    *model_args: Any,\n",
    "    current_activation_name: str,\n",
    "    current_hook: Any,\n",
    "    names_filter: NamesFilter = None,\n",
    "    device: DeviceType = None,\n",
    "    remove_batch_dim: bool = False,\n",
    "    incl_bwd: bool = False,\n",
    "    reset_hooks_end: bool = True,\n",
    "    clear_contexts: bool = False,\n",
    "    pos_slice: Optional[Union[Slice, SliceInput]] = None,\n",
    "    **model_kwargs: Any,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs the model and returns the model output and a Cache object.\n",
    "    \n",
    "    Adds an extra forward hook (current_activation_name, current_hook) to the hooks.\n",
    "\n",
    "    Args:\n",
    "        *model_args: Positional arguments for the model.\n",
    "        current_activation_name: The name of the activation to hook.\n",
    "        current_hook: The hook function to use.\n",
    "        names_filter (NamesFilter, optional): A filter for which activations to cache.\n",
    "        device (str or torch.Device, optional): The device to cache activations on.\n",
    "        remove_batch_dim (bool, optional): If True, removes the batch dimension when caching.\n",
    "        incl_bwd (bool, optional): If True, caches gradients as well.\n",
    "        reset_hooks_end (bool, optional): If True, removes all hooks added by this function.\n",
    "        clear_contexts (bool, optional): If True, clears hook contexts whenever hooks are reset.\n",
    "        pos_slice: The slice to apply to the cache output. Defaults to None.\n",
    "        **model_kwargs: Keyword arguments for the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the model output and a Cache object.\n",
    "    \"\"\"\n",
    "\n",
    "    pos_slice = Slice.unwrap(pos_slice)\n",
    "\n",
    "    # Get the caching hooks\n",
    "    cache_dict, fwd, bwd = self.get_caching_hooks(\n",
    "        names_filter,\n",
    "        incl_bwd,\n",
    "        device,\n",
    "        remove_batch_dim=remove_batch_dim,\n",
    "        pos_slice=pos_slice,\n",
    "    )\n",
    "\n",
    "    # Add the extra forward hook\n",
    "    fwd_hooks = [(current_activation_name, current_hook)] + fwd\n",
    "\n",
    "    # Run the model with the hooks\n",
    "    with self.hooks(\n",
    "        fwd_hooks=fwd_hooks,\n",
    "        bwd_hooks=bwd,\n",
    "        reset_hooks_end=reset_hooks_end,\n",
    "        clear_contexts=clear_contexts,\n",
    "    ):\n",
    "        model_out = self(*model_args, **model_kwargs)\n",
    "        if incl_bwd:\n",
    "            model_out.backward()\n",
    "\n",
    "    return model_out, cache_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37af0a3-9ac1-403f-b458-7ab5e7fc648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attach the new method to the model instance\n",
    "model.run_with_cache_with_extra_hook = types.MethodType(run_with_cache_with_extra_hook, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f61287fe-e09f-4b16-95b0-32983d145a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generic_activation_patch(\n",
    "    model: HookedTransformer,\n",
    "    corrupted_tokens: Int[torch.Tensor, \"batch pos\"],\n",
    "    clean_cache: ActivationCache,\n",
    "    patching_metric: Callable[[Float[torch.Tensor, \"batch pos d_vocab\"]], Float[torch.Tensor, \"\"]],\n",
    "    patch_setter: Callable[\n",
    "        [CorruptedActivation, Sequence[int], ActivationCache], PatchedActivation\n",
    "    ],\n",
    "    activation_name: str,\n",
    "    index_axis_names: Optional[Sequence[AxisNames]] = None,\n",
    "    index_df: Optional[pd.DataFrame] = None,\n",
    "    return_index_df: bool = False,\n",
    ") -> Union[torch.Tensor, Tuple[torch.Tensor, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    A generic function to do activation patching, will be specialised to specific use cases.\n",
    "\n",
    "    Activation patching is about studying the counterfactual effect of a specific activation between a clean run and a corrupted run. The idea is have two inputs, clean and corrupted, which have two different outputs, and differ in some key detail. Eg \"The Eiffel Tower is in\" vs \"The Colosseum is in\". Then to take a cached set of activations from the \"clean\" run, and a set of corrupted.\n",
    "\n",
    "    Internally, the key function comes from three things: A list of tuples of indices (eg (layer, position, head_index)), a index_to_act_name function which identifies the right activation for each index, a patch_setter function which takes the corrupted activation, the index and the clean cache, and a metric for how well the patched model has recovered.\n",
    "\n",
    "    The indices can either be given explicitly as a pandas dataframe, or by listing the relevant axis names and having them inferred from the tokens and the model config. It is assumed that the first column is always layer.\n",
    "\n",
    "    This function then iterates over every tuple of indices, does the relevant patch, and stores it\n",
    "\n",
    "    Args:\n",
    "        model: The relevant model\n",
    "        corrupted_tokens: The input tokens for the corrupted run\n",
    "        clean_cache: The cached activations from the clean run\n",
    "        patching_metric: A function from the model's output logits to some metric (eg loss, logit diff, etc)\n",
    "        patch_setter: A function which acts on (corrupted_activation, index, clean_cache) to edit the activation and patch in the relevant chunk of the clean activation\n",
    "        activation_name: The name of the activation being patched\n",
    "        index_axis_names: The names of the axes to (fully) iterate over, implicitly fills in index_df\n",
    "        index_df: The dataframe of indices, columns are axis names and each row is a tuple of indices. Will be inferred from index_axis_names if not given. When this is input, the output will be a flattened tensor with an element per row of index_df\n",
    "        return_index_df: A Boolean flag for whether to return the dataframe of indices too\n",
    "\n",
    "    Returns:\n",
    "        patched_output: The tensor of the patching metric for each patch. By default it has one dimension for each index dimension, via index_df set explicitly it is flattened with one element per row.\n",
    "        index_df *optional*: The dataframe of indices\n",
    "    \"\"\"\n",
    "\n",
    "    if index_df is None:\n",
    "        assert index_axis_names is not None\n",
    "\n",
    "        # Get the max range for all possible axes\n",
    "        max_axis_range = {\n",
    "            \"layer\": model.cfg.n_layers,\n",
    "            \"pos\": corrupted_tokens.shape[-1],\n",
    "            \"head_index\": model.cfg.n_heads,\n",
    "        }\n",
    "        max_axis_range[\"src_pos\"] = max_axis_range[\"pos\"]\n",
    "        max_axis_range[\"dest_pos\"] = max_axis_range[\"pos\"]\n",
    "        max_axis_range[\"head\"] = max_axis_range[\"head_index\"]\n",
    "\n",
    "        # Get the max range for each axis we iterate over\n",
    "        index_axis_max_range = [max_axis_range[axis_name] for axis_name in index_axis_names]\n",
    "\n",
    "        # Get the dataframe where each row is a tuple of indices\n",
    "        index_df = transformer_lens.patching.make_df_from_ranges(index_axis_max_range, index_axis_names)\n",
    "\n",
    "        flattened_output = False\n",
    "    else:\n",
    "        # A dataframe of indices was provided. Verify that we did not *also* receive index_axis_names\n",
    "        assert index_axis_names is None\n",
    "        index_axis_max_range = index_df.max().to_list()\n",
    "\n",
    "        flattened_output = True\n",
    "\n",
    "    # Create an empty tensor to show the patched metric for each patch\n",
    "    if flattened_output:\n",
    "        patched_metric_output = torch.zeros(len(index_df), device=model.cfg.device)\n",
    "    else:\n",
    "        patched_metric_output = torch.zeros(index_axis_max_range, device=model.cfg.device)\n",
    "\n",
    "    # A generic patching hook - for each index, it applies the patch_setter appropriately to patch the activation\n",
    "    def patching_hook(corrupted_activation, hook, index, clean_activation):\n",
    "        return patch_setter(corrupted_activation, index, clean_activation)\n",
    "\n",
    "    # Iterate over every list of indices, and make the appropriate patch!\n",
    "    for c, index_row in enumerate(tqdm((list(index_df.iterrows())))):\n",
    "        index = index_row[1].to_list()\n",
    "\n",
    "        # The current activation name is just the activation name plus the layer (assumed to be the first element of the input)\n",
    "        current_activation_name = utils.get_act_name(activation_name, layer=index[0])\n",
    "\n",
    "        # The hook function cannot receive additional inputs, so we use partial to include the specific index and the corresponding clean activation\n",
    "        current_hook = partial(\n",
    "            patching_hook,\n",
    "            index=index,\n",
    "            clean_activation=clean_cache[current_activation_name],\n",
    "        )\n",
    "        \n",
    "#         incl_bwd = False\n",
    "#         cache_dict, fwd, bwd = model.get_caching_hooks(\n",
    "#             incl_bwd=incl_bwd,\n",
    "#             device=device,\n",
    "#             names_filter=None\n",
    "#         )\n",
    "        \n",
    "#         fwd_hooks = [(current_activation_name, current_hook)] + fwd\n",
    "        # Run the model with the patching hook and get the logits!\n",
    "        # patched_logits, patched_cache = \"\", \"\"\n",
    "        \n",
    "        patched_logits, patched_cache = model.run_with_cache_with_extra_hook(\n",
    "            corrupted_tokens, \n",
    "            current_activation_name=current_activation_name, \n",
    "            current_hook= current_hook\n",
    "        )\n",
    "        # print(patched_cache.keys())\n",
    "        # print(patched_logits.shape)\n",
    "\n",
    "        # Calculate the patching metric and store\n",
    "        if flattened_output:\n",
    "            patched_metric_output[c] = patching_metric(patched_cache).item()\n",
    "        else:\n",
    "            patched_metric_output[tuple(index)] = patching_metric(patched_cache).item()\n",
    "\n",
    "    if return_index_df:\n",
    "        return patched_metric_output, index_df\n",
    "    else:\n",
    "        return patched_metric_output\n",
    "\n",
    "def layer_pos_patch_setter(corrupted_activation, index, clean_activation):\n",
    "    \"\"\"\n",
    "    Applies the activation patch where index = [layer, pos]\n",
    "\n",
    "    Implicitly assumes that the activation axis order is [batch, pos, ...], which is true of everything that is not an attention pattern shaped tensor.\n",
    "    \"\"\"\n",
    "    assert len(index) == 2\n",
    "    layer, pos = index\n",
    "    corrupted_activation[:, pos, ...] = clean_activation[:, pos, ...]\n",
    "    return corrupted_activation\n",
    "    \n",
    "get_act_patch_resid_pre = partial(\n",
    "    generic_activation_patch,\n",
    "    patch_setter=layer_pos_patch_setter,\n",
    "    activation_name=\"resid_pre\",\n",
    "    index_axis_names=(\"layer\", \"pos\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e845d26-85d2-47c8-aa08-4b84956a4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_feature_metric(cache):\n",
    "    sae_in = cache[sae.cfg.hook_name]\n",
    "    feature_acts = sae.encode(sae_in)\n",
    "    # print(feature_acts.shape)\n",
    "    feature_acts = feature_acts.squeeze()\n",
    "    return feature_acts[:, :, 15191][-2:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca48742-64ce-425c-aa39-5df588b549da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_pr)\n",
    "corrupted_tokens = model.to_tokens(corr_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652fb0d5-3404-4c99-a266-5c44ccd7e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fe305-8fa0-40bd-8c00-6f7fc6c23ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_pre_act_patch_results = get_act_patch_resid_pre(model, corrupted_tokens, clean_cache, equal_feature_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb07858b-195b-48cc-bde6-79eaada658aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 23.5642,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 23.5370,  2.7963,  2.8199,  2.8341,  2.7722,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 24.1331,  2.8042,  2.8268,  5.2053,  2.6619,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 23.6086,  2.9299,  5.2871,  3.0597,  2.6450,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 20.0806,  5.5723,  5.6269,  3.1798,  2.6530,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 14.6763,  6.5523,  6.2608,  6.0508,  5.4315,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504, 10.3021,  7.1756,  6.7306,  8.0341,  5.4613,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  9.6613,  9.5132,  6.4422,  8.4105,  5.5200,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  7.0548,  8.8149,  6.2288,  8.1243,  7.6363,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  5.8952,  2.8504,  2.8504, 14.1238,  9.2461],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504],\n",
       "        [ 2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,\n",
       "          2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504,  2.8504]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resid_pre_act_patch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e557b9a5-6efe-4aa3-95fa-b45bb59af0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neel_plotly import line, imshow, scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34d7bfa3-5b29-4781-ae73-95ffa774afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = imshow(\n",
    "    resid_pre_act_patch_results, \n",
    "    yaxis=\"Layer\", \n",
    "    xaxis=\"Position\", \n",
    "    x=[f\"{tok} {i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))],\n",
    "    title=\"resid_pre Activation Patching\",\n",
    "    return_fig=True  # This ensures the figure object is returned\n",
    ")\n",
    "\n",
    "fig.write_image(\"resid_pre_activation_patching.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2a2de-d748-4aa3-88e3-77a4093e99be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b8afc-f64a-47d5-9c5a-74ec43089d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262883bf-80d7-466d-81b0-1162c09c28e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5f0ac41-33a1-4122-b90a-6db2b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_head_vector_patch_setter(\n",
    "    corrupted_activation,\n",
    "    index,\n",
    "    clean_activation,\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies the activation patch where index = [layer,  head_index]\n",
    "\n",
    "    Implicitly assumes that the activation axis order is [batch, pos, head_index, ...], which is true of all attention head vector activations (q, k, v, z, result) but *not* of attention patterns.\n",
    "    \"\"\"\n",
    "    assert len(index) == 2\n",
    "    layer, head_index = index\n",
    "    corrupted_activation[:, :, head_index] = clean_activation[:, :, head_index]\n",
    "\n",
    "    return corrupted_activation\n",
    "\n",
    "get_act_patch_attn_head_out_all_pos = partial(\n",
    "    generic_activation_patch,\n",
    "    patch_setter=layer_head_vector_patch_setter,\n",
    "    activation_name=\"z\",\n",
    "    index_axis_names=(\"layer\", \"head\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e3642-32f2-48af-8b89-260ef0834adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_head_out_all_pos_act_patch_results = get_act_patch_attn_head_out_all_pos(model, corrupted_tokens, clean_cache, equal_feature_metric)\n",
    "fig = imshow(attn_head_out_all_pos_act_patch_results,  \n",
    "       yaxis=\"Layer\", \n",
    "       xaxis=\"Head\", \n",
    "       title=\"attn_head_out Activation Patching (All Pos)\", \n",
    "        return_fig=True)\n",
    "\n",
    "fig.write_image(\"attn_head_out Activation Patching All Pos.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee685f-1a96-4660-ae2c-885f1eaa2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa15ed9-93ed-4598-a218-69213d4a0408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bc007-f963-40a2-b89f-d64b73af0662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3594621-7cd7-45de-8814-22128c5954bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_pos_head_vector_patch_setter(\n",
    "    corrupted_activation,\n",
    "    index,\n",
    "    clean_activation,\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies the activation patch where index = [layer, pos, head_index]\n",
    "\n",
    "    Implicitly assumes that the activation axis order is [batch, pos, head_index, ...], which is true of all attention head vector activations (q, k, v, z, result) but *not* of attention patterns.\n",
    "    \"\"\"\n",
    "    assert len(index) == 3\n",
    "    layer, pos, head_index = index\n",
    "    corrupted_activation[:, pos, head_index] = clean_activation[:, pos, head_index]\n",
    "    return corrupted_activation\n",
    "\n",
    "get_act_patch_attn_head_out_by_pos = partial(\n",
    "    generic_activation_patch,\n",
    "    patch_setter=layer_pos_head_vector_patch_setter,\n",
    "    activation_name=\"z\",\n",
    "    index_axis_names=(\"layer\", \"pos\", \"head\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "127decc7-4673-4c79-90a5-ac2e2e0047ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033458ad32674e879c7b32157ea31c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DO_SLOW_RUNS = True\n",
    "ALL_HEAD_LABELS = [f\"L{i}H{j}\" for i in range(model.cfg.n_layers) for j in range(model.cfg.n_heads)]\n",
    "if DO_SLOW_RUNS:\n",
    "    attn_head_out_act_patch_results = get_act_patch_attn_head_out_by_pos(model, corrupted_tokens, clean_cache, equal_feature_metric)\n",
    "    attn_head_out_act_patch_results = einops.rearrange(attn_head_out_act_patch_results, \"layer pos head -> (layer head) pos\")\n",
    "    fig = imshow(attn_head_out_act_patch_results, \n",
    "        yaxis=\"Head Label\", \n",
    "        xaxis=\"Pos\", \n",
    "        x=[f\"{tok} {i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))],\n",
    "        y=ALL_HEAD_LABELS,\n",
    "        title=\"attn_head_out Activation Patching By Pos\", \n",
    "        return_fig=True)\n",
    "    fig.write_image(\"attn_head_out_act_patch_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3c21f15-2711-4abf-819d-4e2e90e04b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208, 15])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_head_out_act_patch_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffd97326-70da-4419-9ee8-528ee3126ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming attn_head_out_act_patch_results is your tensor\n",
    "sliced_results = attn_head_out_act_patch_results[:72, -7:]\n",
    "# Adjust the y-axis labels for the first 72 elements\n",
    "sliced_y_labels = ALL_HEAD_LABELS[:72]\n",
    "\n",
    "# Adjust the x-axis labels for the last 7 positions\n",
    "sliced_x_labels = [f\"{tok} {i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))][-7:]\n",
    "\n",
    "fig = imshow(\n",
    "    sliced_results, \n",
    "    yaxis=\"Head Label\", \n",
    "    xaxis=\"Pos\", \n",
    "    x=sliced_x_labels,\n",
    "    y=sliced_y_labels,\n",
    "    title=\"attn_head_out Activation Patching By Pos\", \n",
    "    width=1000,  # Increase the width of the figure\n",
    "    height=1200,  # Increase the height of the figure\n",
    "    return_fig=True\n",
    ")\n",
    "\n",
    "# Optionally, you can adjust the tickfont size for better readability\n",
    "fig.update_layout(\n",
    "    yaxis=dict(tickfont=dict(size=10)),  # Adjust the size as needed\n",
    "    xaxis=dict(tickfont=dict(size=10))   # Adjust the size as needed\n",
    ")\n",
    "\n",
    "# Save the figure\n",
    "fig.write_image(\"attn_head_out_act_patch_results_sliced.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2019c85-0912-4ee2-bf8e-e07aa310ceff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('L2H1', '6 11', 5.30517578125),\n",
       " ('L2H5', ' plus 9', 6.3087568283081055),\n",
       " ('L3H2', ' plus 9', 5.351902008056641),\n",
       " ('L3H4', ' plus 9', 5.247307777404785),\n",
       " ('L3H6', '6 11', 5.364980697631836),\n",
       " ('L4H0', ' ? 13', 5.629123210906982),\n",
       " ('L4H1', '  10', 5.518120765686035),\n",
       " ('L4H1', '6 11', 5.378449440002441),\n",
       " ('L4H1', '7 12', 5.5230021476745605),\n",
       " ('L4H2', '7 12', 5.488124370574951),\n",
       " ('L4H6', ' ? 13', 5.429757118225098),\n",
       " ('L5H0', '7 12', 5.438570976257324),\n",
       " ('L5H1', '  10', 5.3226399421691895),\n",
       " ('L5H1', '6 11', 5.492075443267822),\n",
       " ('L5H1', '7 12', 5.903805732727051),\n",
       " ('L5H1', ' ? 13', 5.319910049438477),\n",
       " ('L5H4', ' ? 13', 5.545135498046875),\n",
       " ('L6H0', ' plus 9', 5.626616954803467),\n",
       " ('L6H0', ' ? 13', 0.0),\n",
       " ('L6H4', '7 12', 5.299982070922852),\n",
       " ('L6H5', '7 12', 5.293205261230469),\n",
       " ('L7H0', ' ? 13', 5.8349199295043945),\n",
       " ('L7H1', ' ? 13', 5.990413188934326),\n",
       " ('L7H3', ' ? 13', 6.422385215759277),\n",
       " ('L7H4', '7 12', 5.271982192993164),\n",
       " ('L7H7', ' ? 13', 5.491620063781738),\n",
       " ('L8H3', ' ? 13', 10.468521118164062),\n",
       " ('L8H5', ' ? 13', 0.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming sliced_results is your sliced tensor\n",
    "mean_value = sliced_results.mean().item()\n",
    "std_dev = sliced_results.std().item()\n",
    "\n",
    "# Calculate the threshold for one standard deviation away from the mean\n",
    "lower_threshold = mean_value - std_dev\n",
    "upper_threshold = mean_value + std_dev\n",
    "\n",
    "# Identify the indices where the values are one standard deviation away from the mean\n",
    "indices = (sliced_results < lower_threshold) | (sliced_results > upper_threshold)\n",
    "y_indices, x_indices = torch.where(indices)\n",
    "\n",
    "# Extract the corresponding y labels, x labels, and values\n",
    "tuples_list = [\n",
    "    (sliced_y_labels[y_idx], sliced_x_labels[x_idx], sliced_results[y_idx, x_idx].item())\n",
    "    for y_idx, x_idx in zip(y_indices, x_indices)\n",
    "]\n",
    "\n",
    "# Display the tuples\n",
    "tuples_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e8e51c4-14aa-4bde-bdfb-932d9960dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1),\n",
       " (2, 5),\n",
       " (3, 2),\n",
       " (3, 4),\n",
       " (3, 6),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 1),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 6),\n",
       " (5, 0),\n",
       " (5, 1),\n",
       " (5, 1),\n",
       " (5, 1),\n",
       " (5, 1),\n",
       " (5, 4),\n",
       " (6, 0),\n",
       " (6, 0),\n",
       " (6, 4),\n",
       " (6, 5),\n",
       " (7, 0),\n",
       " (7, 1),\n",
       " (7, 3),\n",
       " (7, 4),\n",
       " (7, 7),\n",
       " (8, 3),\n",
       " (8, 5)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert L2H1 format to (2, 1)\n",
    "def convert_to_tuple(layer_head_str):\n",
    "    layer = int(layer_head_str[1])\n",
    "    head = int(layer_head_str[3])\n",
    "    return (layer, head)\n",
    "\n",
    "# Convert the first element of each tuple in the list\n",
    "converted_tuples = [convert_to_tuple(item[0]) for item in tuples_list] #[(convert_to_tuple(item[0]), item[1], item[2]) for item in tuples_list]\n",
    "\n",
    "# Display the result\n",
    "converted_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963b04c-d415-4537-9406-a40d4e92f1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94bb33f6-5447-41a1-93b6-220a4ec1bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2ac6a21-6b64-47d3-93e1-32483f87c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_att_pattern = clean_cache['blocks.2.attn.hook_pattern'][0, 1, :, :] #.shape  #.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa242d40-4750-4b9d-b254-f606e41407a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_relevant_attention_patterns(clean_cache, layer_head_tuples):\n",
    "    for layer_ind, head_ind in layer_head_tuples:\n",
    "        temp_att_pattern = clean_cache[f'blocks.{layer_ind}.attn.hook_pattern'][1, head_ind, :, :]\n",
    "        attention_pattern = temp_att_pattern.detach().cpu().numpy()\n",
    "        # Define the x and y labels, assuming they correspond to tokens\n",
    "        tokens = model.to_str_tokens(clean_tokens[0])\n",
    "        labels = [f\"{tok} {i}\" for i, tok in enumerate(tokens)]\n",
    "\n",
    "        # Generate the heatmap\n",
    "        fig = px.imshow(\n",
    "            attention_pattern,\n",
    "            labels=dict(x=\"Head Position\", y=\"Head Position\", color=\"Attention\"),\n",
    "            x=labels,\n",
    "            y=labels,\n",
    "            title=f\"Attention Pattern in Layer {layer_ind}, Head {head_ind}\",\n",
    "            color_continuous_scale=\"Blues\"\n",
    "        )\n",
    "        # Display the figure\n",
    "        fig.write_image(f\"equal_feature_operator_heads/L{layer_ind}H{head_ind}_atten_pattern.png\")\n",
    "        \n",
    "save_relevant_attention_patterns(clean_cache, converted_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17d2e72e-3738-4651-88aa-f1f78d3bc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import torch\n",
    "\n",
    "# Assuming attention_pattern is a PyTorch tensor\n",
    "attention_pattern = temp_att_pattern.detach().cpu().numpy()  # Convert to numpy for plotting\n",
    "\n",
    "# Define the x and y labels, assuming they correspond to tokens\n",
    "tokens = model.to_str_tokens(clean_tokens[0])\n",
    "labels = [f\"{tok} {i}\" for i, tok in enumerate(tokens)]\n",
    "\n",
    "# Generate the heatmap\n",
    "fig = px.imshow(\n",
    "    attention_pattern,\n",
    "    labels=dict(x=\"Head Position\", y=\"Head Position\", color=\"Attention\"),\n",
    "    x=labels,\n",
    "    y=labels,\n",
    "    title=\"Attention Pattern in Block 2, Head 1\",\n",
    "    color_continuous_scale=\"Blues\"\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "fig.write_image(\"L2H1_atten_pattern.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ca12c-dbde-4d77-94bb-77cb381477a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390e9d9-7406-4c38-bb6e-140900158be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55fb14-091d-4cba-a8b6-7fe45e469b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e76d98-c826-45cc-9042-d57c444c32c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a4eb5d4-4e9c-476d-911d-0422221673bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformerConfig:\n",
       "{'act_fn': 'gelu_pytorch_tanh',\n",
       " 'attention_dir': 'causal',\n",
       " 'attn_only': False,\n",
       " 'attn_scale': 16.0,\n",
       " 'attn_scores_soft_cap': 50.0,\n",
       " 'attn_types': ['global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local',\n",
       "                'global',\n",
       "                'local'],\n",
       " 'checkpoint_index': None,\n",
       " 'checkpoint_label_type': None,\n",
       " 'checkpoint_value': None,\n",
       " 'd_head': 256,\n",
       " 'd_mlp': 9216,\n",
       " 'd_model': 2304,\n",
       " 'd_vocab': 256000,\n",
       " 'd_vocab_out': 256000,\n",
       " 'decoder_start_token_id': None,\n",
       " 'default_prepend_bos': True,\n",
       " 'device': 'cuda',\n",
       " 'dtype': torch.float32,\n",
       " 'eps': 1e-06,\n",
       " 'experts_per_token': None,\n",
       " 'final_rms': True,\n",
       " 'from_checkpoint': False,\n",
       " 'gated_mlp': True,\n",
       " 'init_mode': 'gpt2',\n",
       " 'init_weights': False,\n",
       " 'initializer_range': 0.02,\n",
       " 'load_in_4bit': False,\n",
       " 'model_name': 'gemma-2-2b',\n",
       " 'n_ctx': 8192,\n",
       " 'n_devices': 1,\n",
       " 'n_heads': 8,\n",
       " 'n_key_value_heads': 4,\n",
       " 'n_layers': 26,\n",
       " 'n_params': 2146959360,\n",
       " 'normalization_type': 'RMSPre',\n",
       " 'num_experts': None,\n",
       " 'original_architecture': 'Gemma2ForCausalLM',\n",
       " 'output_logits_soft_cap': 30.0,\n",
       " 'parallel_attn_mlp': False,\n",
       " 'positional_embedding_type': 'rotary',\n",
       " 'post_embedding_ln': False,\n",
       " 'relative_attention_max_distance': None,\n",
       " 'relative_attention_num_buckets': None,\n",
       " 'rotary_adjacent_pairs': False,\n",
       " 'rotary_base': 10000.0,\n",
       " 'rotary_dim': 256,\n",
       " 'scale_attn_by_inverse_layer_idx': False,\n",
       " 'seed': None,\n",
       " 'tie_word_embeddings': False,\n",
       " 'tokenizer_name': 'google/gemma-2-2b',\n",
       " 'tokenizer_prepends_bos': True,\n",
       " 'trust_remote_code': False,\n",
       " 'use_attn_in': False,\n",
       " 'use_attn_result': False,\n",
       " 'use_attn_scale': True,\n",
       " 'use_hook_mlp_in': False,\n",
       " 'use_hook_tokens': False,\n",
       " 'use_local_attn': True,\n",
       " 'use_normalization_before_and_after': True,\n",
       " 'use_split_qkv_input': False,\n",
       " 'window_size': 4096}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc8aa0-8e67-42f9-919e-f75057980345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8e2dc-9359-4c3a-8858-9b0dbec065d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dfffe-5a88-400d-8913-f6834de8c87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-finetuning]",
   "language": "python",
   "name": "conda-env-.conda-finetuning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
